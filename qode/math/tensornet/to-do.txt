As one-offs:
- dummy_test is probably out of date and may not run
- make it such that if a backend it not installed, it does not crash just trying to import them
- should primitive_tensor_wrapper "enforce" the tensor type by running the given tensor through a backend function (but then this would copy data)

===

Questions about using opt_einsum (https://joss.theoj.org/papers/10.21105/joss.00753):
Clearly there are advantages to the fact that the authors of opt_einsum have given much more
thought to their heuristics, but it is not immediately available for all backends, and the
fact that my heuristics live above the backend and need to know nothing about the hardware
to at least make a *good* guess (maybe not the best) still makes it useful.  That said, 
on further study, we might find that opt_einsum is just as easily put on top of other backends
as is my own code (eg, it already works on top of numpy and is default in pytorch).
If that is the case, and we find it is a hands-down winner over my own heuristic, then we can
just have evaluate() pass *all* of the arguments directly to opt_einsum.  This might also
be left as a user choice.

Update:
opt_einsum can now be enabled with the tensorly backend by the use of the following two lines, probably at the top-level:
  tensorly_plugins.use_opt_einsum()
  qode.math.tensornet.backend_contract_path(True)
See also:
  https://tensorly.org/stable/modules/generated/tensorly.plugins.use_opt_einsum.html#tensorly.plugins.use_opt_einsum
  https://optimized-einsum.readthedocs.io/en/stable/install.html#conda
I'm not a big fan of how this works because, IMO, all decisions about how to contract tensors should
be as local as possible.  Say, for example, you wanted to merge two codes that had been using different
backends for the tensors.  It will be a lot more convenient if you don't have to force them to agree on one.
This is why my tensors carry knowledge of their backends with them, and the only thing that matters when
two tensors meet is that they are the same (which is presumably the case within any given code domain).
Now there is this wart, where you insist that all tensors (even those with different backends) are either
going to use the frontend or the backend contraction path.  Probably this is ok for well over 90% of use
cases, but I would like to clean it up.  At the same time though, making the backend_contract_path
option a feature of a backend is also not really (ie, could carry this option around with the tensors)
because it is not a feature of the backend, it is a feature of a contraction within the context of a 
backend.  We certainly do not want to insist that a tensor created with one way of determining the contraction
path cannot be contracted with a tensor with a different "opinion" on the way of determining the contraction
path.  At the moment then, this is the least of evils.  At least a user can dynamically switch back and forth.

===

The main thing(s) to do concern the interaction of the contract() function and the @ operator.

First a bit of "theory."  One can decimate the functionality of the to_contract class and still
preserve the utility of this module.  The only thing the to_contract class *must* do is store
the reference to the tensornet tensor and the indices to be contract/permuted.  Then it can be
given as such as an argument to the contract() function (hence the name "to_contract").

The functionality with the @ operator was added historically later and is implemented as a
somewhat kludgy, thin, and poorly conceived layer on top of to_contract and contract().
However is is really very useful, and so it should just be implemented better.

There is one fundamental issue that I cannot resolve that may remain just a permanent dark
corner to warn users about (but does not interfere with how the code "should" be used)
and probably does not present too much of a tripping hazard or trap door.  It could possibly
even be useful.  This is issue 1 below.

The other issue is just something to clean up, but I'm tired of coding now and I may only
get to it soon if it starts biting me.  It has the effect that exceptions can be raised
quite far away from where the user made the error.  This is issue 2.

Issue 1:

As much as possible, we would like the result of an expression like A(p,1) @ B(p,0) to act
in every way like a tensor itself.  However, the string of tensors to be contracted often
consists of more then two, and so it would be incorrect to assume that a complete and
valid tensor has been described after every use of the @ operator.  Therefore, it is not
safe to assume that the use of @ results in something that is a tensor in every way
(eg, it may not even have a valid shape, due to missing free indices).  By the same token,
since the = operator in python only means "bind" (as opposed to, say, C++), there is no
way for the user to indicate when a tensor description is "done".  The dark corner here
is that the result of several @ operations remembers the names of its contraction indices
and if that result is bound to a variable, it could be @-ed with more tensors, inadvertently
using the same letters, leading to unexpected results.  This is probably not a big deal,
however, because this usage pattern is also unorthodox, since, after binding the result
of an @ string to a name, that object should itself be subjected to the call operation ()
referencing the indices of the finished product (with no memory of labels used for internal
contractions) before being contracted with other tensors.  I'm not sure that there is
a better solution than the one I have now, where to_contract objects simply pretend to be
tensors (ie, they are not child classes of tensor_base, but share some behaviors that
only work without exception if the tensors are complete and valid).

Issue 2:

Currently, building a to_contract object (which acts for all intents and purposes like a
tensor) using chains of @ operations does zero checking to make sure that tensors are
compatible with one another.  This can be fixed because, even with incomplete tensors
(tensors with missing free indices, etc), we can tell if they have the same backend,
and if indices that are either supposed to be contracted or reduces are (so far) of the
same length.  It would be better for the user to raise these exceptions sooner rather 
than later, when the to_contract "tensor" actually is finally used.

One potential solution that "kills two birds with one stone" (inelegant but functional)
is just to have contract() called after every instance of @, and not worry about
missing free indices (free-index "gaps").  The result would only be cached however
(returned by what is presently _resolve_contract_ops()) if it describes a complete and
valid tensor.  This might be better facilitated with nicer internal code aesthetics
if contract() could take a complete to_contract string as an argument.  The best
behavior would be to interpret the multiple arguments of contract as if they had 
all been @-ed together.

A design I would like more for aesthetic reasons would be to let the result of @ be
a child class of tensor_base, but I don't know if it is worth it, since the functionality
would be (?) the same.
